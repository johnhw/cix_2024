{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8th International Summer School on Computational Interaction](imgs/header.png)\n",
    "\n",
    "# 2: Exercise\n",
    "**John H. Williamson**\n",
    "\n",
    "In the exercise, we will experiment with both **forward** and **backward** models. We'll have the live link to the keyboard fist sensor, and you'll be able to test different approaches to interpreting the sensor vector.\n",
    "\n",
    "We'll work in groups for this exercise.\n",
    "\n",
    "## Task\n",
    "You have two parts:\n",
    "\n",
    "* 2(a) Implement/tune the direct inverse model, using the skeleton and instruction below\n",
    "* 2(b) Implement/tune the Bayesian inverse model, using the skeleton and instruction below\n",
    "* TRY THESE MODELS WITH MORE CHALLENGING SENSING CONDITIONS -- see below!\n",
    "\n",
    "## FAQ\n",
    "\n",
    "* I can't run the keyboard model! \n",
    "    * Check if the `sudo` option helps (needed on Linux). If not, find someone else who can run the demo!\n",
    "* I can run the keyboard model, but it doesn't connect to the machine learning!\n",
    "    * This is probably a firewall issue on your laptop. You need to allow port 5556 for localhost traffic.\n",
    "* The predictions are too good even with a simple model!\n",
    "    * Make sure you are making the problem hard enough -- see the model variations below!\n",
    "* The predictions are bad!\n",
    "    * Yes, the default settings are not especially optimal. Also, these are simplified models to not make your life too complicated.\n",
    "* I don't have a group.\n",
    "    * Find a couple of neighbours and form groups of 2-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports (remember to run this cell!)\n",
    "import sys\n",
    "\n",
    "sys.path = [\"src\"] + sys.path\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zmqutils import safe_launch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import jax\n",
    "import pfilter\n",
    "from key_model import multi_simulate\n",
    "from zmqutils import sync_rep_loop\n",
    "\n",
    "\n",
    "# utils...\n",
    "def prediction_loop(predict_fn, port=5556):\n",
    "    # synchronous reply loop -- receive touch events and reply with predictions\n",
    "    def loop_fn(touch_input):\n",
    "        # respond to touch events\n",
    "        if \"touch\" in touch_input:\n",
    "            # decode it, predict and send a response\n",
    "            x = np.array(touch_input[\"touch\"]).astype(np.float32).reshape(1, 270)\n",
    "            seq = touch_input[\"seq\"]\n",
    "            y = predict_fn(x)\n",
    "            msg = {\n",
    "                \"target\": {\n",
    "                    \"x\": float(y[0, 0]),\n",
    "                    \"y\": float(y[0, 1]),\n",
    "                    \"radius\": float(y[0, 2]),\n",
    "                },\n",
    "                \"seq\": seq,\n",
    "            }\n",
    "            print(f\"{seq}                     \\r\", end=\"\")\n",
    "            return msg\n",
    "        # queue shutdown\n",
    "        if \"quit\" in touch_input:\n",
    "            raise StopIteration\n",
    "\n",
    "    sync_rep_loop(port, loop_fn)\n",
    "\n",
    "\n",
    "def offset_plot(true, predicted):\n",
    "    # plot lines between the predicted and actual points\n",
    "    fig, ax = plt.subplots(figsize=(15, 4.5))\n",
    "    ax.scatter(true[:, 0], true[:, 1], label=\"Actual\", marker=\"x\")\n",
    "    predictions = mlp_state.apply_fn(mlp_state.params, X_test)\n",
    "    ax.scatter(predicted[:, 0], predicted[:, 1], label=\"Predicted\", marker=\"o\")\n",
    "    for i in range(len(y_test)):\n",
    "        ax.plot(\n",
    "            [true[i, 0], predicted[i, 0]],\n",
    "            [true[i, 1], predicted[i, 1]],\n",
    "            color=\"black\",\n",
    "            alpha=0.1,\n",
    "        )\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations of the sensor configuration\n",
    "You can make the problem more or less hard by changing the configuration of `key_demo`. \n",
    "\n",
    "You'll find the direct inverse is worse at coping with noise or dropped frames than the Bayesian inverse model, so do try the simulator with different settings.\n",
    "\n",
    "Here are some options you can pass to `key_demo.py`\n",
    "* `--noise` adds noise to the sensor data. 0.1 is a lot.\n",
    "* `--frame_drop` drops this fraction of frames entirely\n",
    "* `--position_drift` adds positional wobble to the sensor data (0.03 is a lot)\n",
    "* `--intensity_std` adds noise to the overall gain (0.5 is a lot)\n",
    "\n",
    "Here are some examples (uncomment and try some):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTRL-ESC to exit!\n",
    "# safe_launch(\"src/key_demo.py\", args=[\"--zmq_port\", \"5556\", \"--noise\", \"0.1\"], timeout=0) # noisy\n",
    "#safe_launch(\"src/key_demo.py\", \n",
    "            args=[\"--zmq_port\", \"5556\", \n",
    "                  \"--frame_drop\", \"0.1\"], timeout=0) # intermittent frame drop\n",
    "# safe_launch(\"src/key_demo.py\", args=[\"--zmq_port\", \"5556\", \"--position_drift\", \"0.02\"], timeout=0) # warbling position\n",
    "# safe_launch(\"src/key_demo.py\", args=[\"--zmq_port\", \"5556\", \"--noise\", \"0.1\",\n",
    "#                                      \"--frame_drop\", \"0.1\", \"--position_drift\", \"0.02\",\n",
    "#                                       \"--intensity_std\",\"0.3\"],\n",
    "#              timeout=0) # many things at once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 (a) Direct inverse model\n",
    "The code below allows you to train and test a direct inverse model. \n",
    "\n",
    "**Things you can do:**\n",
    "* Capture more or new data from the live capture; (you could merge multiple CSV files just by con catenating them, if you want to do this as a group)\n",
    "* Capture data from the **simulator**. You can configure the number of frames to simulate and the parameters of the simulator.\n",
    "* Change the hyperparameters of the model (e.g. learning rate, iterations, etc.) and the loss function\n",
    "* Adjust the network itself (e.g. change the number of layers, activations, size of layers, use convolutional layers, etc.)\n",
    "\n",
    "You can then run the model live against the touch simulator and see how well it works :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Data capture\n",
    "\n",
    "You can either use my original data (`data/clean.csv`) or generate your own data using the following code.  \n",
    "\n",
    "To generate data:\n",
    "* uncomment the `safe_launch` line below. \n",
    "* The keyboard interface will appear\n",
    "* Press your fist somewhere!\n",
    "* Click with the mouse on the centre point of the target\n",
    "* Keep doing this until you are bored.\n",
    "* Press `CTRL-ESC` to quit the capture\n",
    "* Note: calling `safe_launch` will append to the data file each time it is called. Use `--overwrite` to force it to be rewritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual data generation\n",
    "\n",
    "# add \"--overwrite\" to the arguments if you want to overwrite the file\n",
    "#safe_launch(\"src/key_demo.py\", args=[\"--file\", \"data/my_fistpointer_data.csv\"], timeout=1000)\n",
    "# data_file = \"data/my_fistpointer_data.csv\" # your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can use the simulator to generate new data (it will also append to any existing data file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated data generation\n",
    "\n",
    "from key_model import batch_simulate\n",
    "\n",
    "# you can modify these parameters; noise, size and intensity are most relevant\n",
    "simulator_params = {\n",
    "    \"out_file\": \"data/sim_data.csv\",  # output file\n",
    "    \"n\": 1000,  # number of samples\n",
    "    \"x_sampler\": lambda: np.random.uniform(0, 1),  # x coordinate sampling\n",
    "    \"y_sampler\": lambda: np.random.uniform(0, 1),  # y coordinate sampling\n",
    "    \"size_sampler\": lambda: np.random.uniform(0.02, 0.05),  # size sampling\n",
    "    \"intensity_sampler\": lambda: np.random.uniform(0.8, 2),  # intensity sampling\n",
    "    \"noise\": 0.001,  # noise level\n",
    "}\n",
    "\n",
    "# leave size and slc as they are\n",
    "# uncomment to run the simulation\n",
    "#batch_simulate(size=32, slc=[9,30], **simulator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THE DATA FILE TO THE DATA YOU WANT TO USE HERE\n",
    "data_file = \"data/clean.csv\"  # my data at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing -- you shouldn't need to change this cell\n",
    "data = np.loadtxt(data_file, delimiter=\",\").astype(np.float32)\n",
    "print(f\"Read data with shape {data.shape} from {data_file}\")\n",
    "\n",
    "# split the features from the targets\n",
    "data_features, data_targets = data[:, :-2], data[:, -2:]\n",
    "\n",
    "# split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data_targets, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training data has {len(X_train)} samples, test data has {len(X_test)} samples\")\n",
    "assert X_train.shape[1] == 270 and y_train.shape[1] == 2, \"Data has the wrong shape\"\n",
    "assert X_test.shape[1] == 270 and y_test.shape[1] == 2, \"Data has the wrong shape\"\n",
    "print(\"Data read and split successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Parameters\n",
    "You can vary the settings below to change the training and testing behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ME ###\n",
    "\n",
    "# Hyperparameters for training\n",
    "direct_params = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"iterations\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "# Define the loss function (MSE)\n",
    "# You can change this if you wish!\n",
    "def mse_loss(predictions, targets):\n",
    "    return jnp.mean((predictions - targets) ** 2)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    # 270 - 32 -> 2 dimensions\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # x will be a (batch, 270) element tensor\n",
    "        x = nn.Dense(features=32)(x)\n",
    "        x = nn.swish(x)\n",
    "        x = nn.Dense(features=2)(x)  # Output layer with 2 dimensions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Training\n",
    "You don't need to modify the cell below usually. You can run it to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell as it is, unless you are doing something clever!\n",
    "# Define a function to create the train state\n",
    "def create_MLP(rng, learning_rate):\n",
    "    model = MLP()\n",
    "    params = model.init(rng, jnp.ones((1, 270)))\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "\n",
    "# Define the evaluation function (for testing)\n",
    "def evaluate(state, batch):\n",
    "    predictions = state.apply_fn(state.params, batch[\"inputs\"])\n",
    "    loss = mse_loss(predictions, batch[\"targets\"])\n",
    "    return loss\n",
    "\n",
    "\n",
    "# predict an output from a single\n",
    "def predict(state, single_input):\n",
    "    single_input = single_input.reshape(\n",
    "        1, -1\n",
    "    )  # Ensure the input has the shape (1, 270)\n",
    "    prediction = state.apply_fn(state.params, single_input)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# One training step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        predictions = state.apply_fn(params, batch[\"inputs\"])\n",
    "        loss = mse_loss(predictions, batch[\"targets\"])\n",
    "        return loss\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "\n",
    "# Train the model\n",
    "rng = jax.random.PRNGKey(42)\n",
    "learning_rate = direct_params[\"learning_rate\"]\n",
    "mlp_state = create_MLP(rng, learning_rate)\n",
    "batch = {\"inputs\": X_train, \"targets\": y_train}\n",
    "\n",
    "# train loop\n",
    "for i in range(direct_params[\"iterations\"]):\n",
    "    mlp_state, loss = train_step(mlp_state, batch)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i}, Loss {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Offline testing\n",
    "The tests below will give you some idea of how well your model works (but no substitute for live testing!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model, and plot some examples\n",
    "test_batch = {\"inputs\": X_test, \"targets\": y_test}\n",
    "test_loss = evaluate(mlp_state, test_batch)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "predicted = mlp_state.apply_fn(mlp_state.params, X_test)\n",
    "offset_plot(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Live testing\n",
    "\n",
    "The code below will allow you to test your model live against the simulator. Remember to try it in different conditions, not just the default noise level! What works well? What is hard to fix by improving the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTRL-ESC to exit! -- you can add additional params to change noise etc. here\n",
    "safe_launch(\"src/key_demo.py\", args=[\"--zmq_port\", \"5556\"], timeout=0)\n",
    "\n",
    "\n",
    "def ml_predict(y):\n",
    "    x = np.array(y).astype(np.float32).reshape(1, 270)\n",
    "    y = predict(mlp_state, x)\n",
    "    y = np.concatenate([y, np.array([[0.005]])], axis=1)  # add fixed radius\n",
    "    return y\n",
    "\n",
    "\n",
    "prediction_loop(ml_predict, port=5556)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 (b) Bayesian inversion with a particle filter\n",
    "Now, you can try and tune the particle filter for the same task. Note the completely different way this works -- there's no training data at all!\n",
    "\n",
    "\n",
    "**Things you can do:**\n",
    "* Change the hyperparameters (e.g. number of particles, prior sampling proportion)\n",
    "* Adjust the likelihood function (e.g. tweak the tolerance of the similarity kernel, replace it with something else)\n",
    "* Adjust the dynamics model (e.g. increase variance of the dynamics, or change the dynamics model entirely)\n",
    "* **very ambitious** fuse the direct inverse in 2(a) with 2(b) to get a better estimate of the touch location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Parameters\n",
    "You can vary the parameters below to change the behaviour of the particle filter. `tolerance` and `dt` are particularly useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_params = {\n",
    "    \"n_particles\": 100,  # number of particles\n",
    "    \"resample_proportion\": 0.02,\n",
    "    \"dt\": 0.1,  # time step size; larger means \"faster\" dynamics\n",
    "    \"pos_std\": 0.5,  # standard deviation of position noise\n",
    "    \"vel_std\": 0.05,  # standard deviation of velocity noise\n",
    "    \"acc_std\": 0.05,  # standard deviation of acceleration noise\n",
    "    \"tolerance\": 0.3,  # similarity tolerance for observation likelihood (smaller = less tolerant)\n",
    "    \"z_scale\": 0.01,  # effect of fist height on fist size\n",
    "    \"z_bias\": 0.03,  # offset (zero value) for size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Definition\n",
    "The code below should work without modification. It defines the particle filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to change this cell\n",
    "physical_units = np.array([9 / 30, 1, 1])  # account for *physical* units\n",
    "dt = pf_params[\"dt\"]\n",
    "\n",
    "\n",
    "def prior_fn(n):\n",
    "    prior = np.zeros((n, 9))  # pos, vel, acc\n",
    "    prior[:, :3] = np.random.uniform(-0.1, 1.1, (n, 3))  # pos (x,y,z)\n",
    "    prior[:, 3:6] = np.random.normal(0, 0.1, (n, 3))  # vel (dx, dy, dz)\n",
    "    prior[:, 6:9] = np.random.normal(0, 0.01, (n, 3))  # acc (ddx, ddy, ddz)\n",
    "    return prior\n",
    "\n",
    "\n",
    "def deterministic_dynamics_fn(state):\n",
    "    # apply very simple Euler time integration\n",
    "    state[:, :3] += state[:, 3:6] * dt * physical_units  # vel -> pos\n",
    "    state[:, 3:6] += state[:, 6:9] * dt * physical_units  # acc -> vel\n",
    "    state[:, 3:6] *= 0.999  # damp velocity\n",
    "    return state\n",
    "\n",
    "\n",
    "def stochastic_dynamics_fn(state):\n",
    "    noise = np.random.normal(0, 1, size=state.shape)\n",
    "    v = pf_params[\"vel_std\"]\n",
    "    a = pf_params[\"acc_std\"]\n",
    "    p = pf_params[\"pos_std\"]\n",
    "    noise_scale = np.array([p, p, p, v, v, v, a, a, a]) * 0.01\n",
    "    state += noise * noise_scale\n",
    "    return state\n",
    "\n",
    "\n",
    "def observe_fn(state):\n",
    "    return multi_simulate(\n",
    "        size=32,\n",
    "        slc=[9, 30],\n",
    "        xs=state[:, 0],\n",
    "        ys=state[:, 1],\n",
    "        intensities=1.5 + 0 * state[:, 0],\n",
    "        sizes=pf_params[\"z_bias\"] + pf_params[\"z_scale\"] * state[:, 2],\n",
    "        noise=0.0,\n",
    "    )\n",
    "\n",
    "\n",
    "def lik_fn(simulated, real):\n",
    "    real = real.reshape(1, -1)\n",
    "    simulated = simulated.reshape(len(simulated), -1)\n",
    "    return np.exp(\n",
    "        -np.sum((simulated - real) ** 2, axis=1) / pf_params[\"tolerance\"] ** 2\n",
    "    )\n",
    "\n",
    "\n",
    "pf = pfilter.ParticleFilter(\n",
    "    prior_fn,\n",
    "    weight_fn=lik_fn,\n",
    "    observe_fn=observe_fn,\n",
    "    dynamics_fn=deterministic_dynamics_fn,\n",
    "    noise_fn=stochastic_dynamics_fn,\n",
    "    n_particles=pf_params[\"n_particles\"],\n",
    "    resample_proportion=pf_params[\"resample_proportion\"],\n",
    ")\n",
    "\n",
    "\n",
    "def process_frame(pf, frame):\n",
    "    if np.sum(frame) == 0:  # blank frame, update but don't correct\n",
    "        pf.update(observed=None)\n",
    "    else:\n",
    "        pf.update(observed=frame)\n",
    "    # convert samples into summary statistics\n",
    "    mean = pf.mean_state[:2]\n",
    "    radius = np.std(pf.original_particles[:,0])\n",
    "    # same format as the direct inverse: x, y, r\n",
    "    return np.array([[mean[0], mean[1], radius]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Offline testing\n",
    "This code just lets you test that nothing is broken. It will not give you a good idea of how well your model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, sanity check the sampling!\n",
    "samples = prior_fn(2)\n",
    "samples = deterministic_dynamics_fn(samples)\n",
    "samples = stochastic_dynamics_fn(samples)\n",
    "observations = observe_fn(samples)\n",
    "weights = lik_fn(observations, observations[0])\n",
    "pf.update(None)  # test filter is working okay\n",
    "pf.update(observed=observations[0])\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 9))\n",
    "axs[0].imshow(\n",
    "    observations[0],\n",
    "    cmap=\"magma\",\n",
    "    aspect=\"auto\",\n",
    "    extent=[0, 1, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    origin=\"lower\",\n",
    ")\n",
    "axs[1].imshow(\n",
    "    observations[1],\n",
    "    cmap=\"magma\",\n",
    "    aspect=\"auto\",\n",
    "    extent=[0, 1, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    origin=\"lower\",\n",
    ")\n",
    "fig.suptitle(\"Simulated observations\")\n",
    "axs[0].scatter(samples[0, 0], samples[0, 1], color=\"green\")\n",
    "axs[1].scatter(samples[1, 0], samples[1, 1], color=\"green\")\n",
    "\n",
    "print(\"Weights (should be [1.0, <1.0])\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run against an offline trace, and plot the results\n",
    "# There is no ground truth here; this just gives you a \n",
    "# sense if the trajectories look like smooth-ish cycles.\n",
    "test_trajectory = np.loadtxt(\"data/circle.csv\", delimiter=\",\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 4.5))\n",
    "pf.init_filter()\n",
    "for i, row in enumerate(test_trajectory):\n",
    "    pf.update(row[:270].reshape(9,30))\n",
    "    x, y = pf.mean_state[:2]\n",
    "    ax.scatter(x, y, s=1, \n",
    "               alpha=0.5, c=plt.get_cmap('viridis')(i/len(test_trajectory)))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Live testing\n",
    "\n",
    "Finally, live testing. Again, what works well here? What can't you easily fix by adapting the model? How does it compare to the direct inversion model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTRL-ESC to exit!\n",
    "safe_launch(\"src/key_demo.py\", args=[\"--zmq_port\", \"5556\"], timeout=0)\n",
    "\n",
    "# initialize the filter and create the prediction callback\n",
    "pf.init_filter()\n",
    "def pf_predict(y):\n",
    "    x = np.array(y).astype(np.float32).reshape(9, 30)\n",
    "    y = process_frame(pf, x)\n",
    "    return y\n",
    "\n",
    "# start predicting\n",
    "prediction_loop(pf_predict, port=5556)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Report back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MENTIMETER**: Put your comments on what you've found out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF EXERCISE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
